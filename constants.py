"""
このファイルは、固定の文字列や数値などのデータを変数として一括管理するファイルです。
"""

############################################################
# ライブラリの読み込み
############################################################
from langchain_community.document_loaders import PyMuPDFLoader, Docx2txtLoader, TextLoader
from langchain_community.document_loaders.csv_loader import CSVLoader


############################################################
# 共通変数の定義
############################################################

# ==========================================
# 画面表示系
# ==========================================
APP_NAME = "社内情報特化型生成AI検索アプリ"
ANSWER_MODE_1 = "社内文書検索"
ANSWER_MODE_2 = "社内問い合わせ"
CHAT_INPUT_HELPER_TEXT = "こちらからメッセージを送信してください。"
DOC_SOURCE_ICON = ":material/description: "
LINK_SOURCE_ICON = ":material/link: "
WARNING_ICON = ":material/warning:"
ERROR_ICON = ":material/error:"
SPINNER_TEXT = "回答生成中..."


# ==========================================
# ログ出力系
# ==========================================
LOG_DIR_PATH = "./logs"
LOGGER_NAME = "ApplicationLog"
LOG_FILE = "application.log"
APP_BOOT_MESSAGE = "アプリが起動されました。"


# ==========================================
# LLM設定系
# ==========================================
MODEL = "gpt-4o-mini"
### 2026/01/02 m.sonoki mod start
# TEMPERATURE = 0.5
TEMPERATURE = 0.0  # 決定的な応答を得るため0に設定
### 2026/01/02 m.sonoki mod end

### 2026/01/02 m.sonoki add start
# ==========================================
# RAG設定系
# ==========================================
# CHUNK_SIZE = 500
# CHUNK_OVERLAP = 50
# MAX_RELATED_DOCUMENTS = 5
CHUNK_SIZE = 350  # セクション境界で確実に分割されるサイズ
CHUNK_OVERLAP = 0  # セクション間での混同を防ぐためオーバーラップなし
MAX_RELATED_DOCUMENTS = 12  # 人事部全9名＋マージンで確実に取得
### 2026/01/02 m.sonoki add end

# ==========================================
# RAG参照用のデータソース系
# ==========================================
RAG_TOP_FOLDER_PATH = "./data"
SUPPORTED_EXTENSIONS = {
    ### 2026/01/02 m.sonoki add start
    ".txt": lambda path: TextLoader(path, encoding="utf-8"),
    ### 2026/01/02 m.sonoki add end
    ".pdf": PyMuPDFLoader,
    ".docx": Docx2txtLoader,
    ### 2026/01/02 m.sonoki mod start (CSVを統合ドキュメントとして読み込むため、file_load関数内で処理)
    # ".csv": lambda path: CSVLoader(path, encoding="utf-8")
    ".csv": "custom"  # initialize.pyのfile_load関数で特別処理
    ### 2026/01/02 m.sonoki mod end
}
WEB_URL_LOAD_TARGETS = [
    "https://generative-ai.web-camp.io/"
]


# ==========================================
# プロンプトテンプレート
# ==========================================
SYSTEM_PROMPT_CREATE_INDEPENDENT_TEXT = "会話履歴と最新の入力をもとに、会話履歴なしでも理解できる独立した入力テキストを生成してください。"

SYSTEM_PROMPT_DOC_SEARCH = """
    あなたは社内の文書検索アシスタントです。
    以下の条件に基づき、ユーザー入力に対して回答してください。

    【条件】
    1. ユーザー入力内容と以下の文脈との間に関連性がある場合、空文字「""」を返してください。
    2. ユーザー入力内容と以下の文脈との関連性が明らかに低い場合、「該当資料なし」と回答してください。

    【文脈】
    {context}
"""

### 2026/01/02 m.sonoki mod start
# SYSTEM_PROMPT_INQUIRY = """
#     あなたは社内情報特化型のアシスタントです。
#     以下の条件に基づき、ユーザー入力に対して回答してください。

#     【条件】
#     1. ユーザー入力内容と以下の文脈との間に関連性がある場合のみ、以下の文脈に基づいて回答してください。
#     2. ユーザー入力内容と以下の文脈との関連性が明らかに低い場合、「回答に必要な情報が見つかりませんでした。」と回答してください。
#     3. 憶測で回答せず、あくまで以下の文脈を元に回答してください。
#     4. できる限り詳細に、マークダウン記法を使って回答してください。
#     5. マークダウン記法で回答する際にhタグの見出しを使う場合、最も大きい見出しをh3としてください。
#     6. 複雑な質問の場合、各項目についてそれぞれ詳細に回答してください。
#     7. 必要と判断した場合は、以下の文脈に基づかずとも、一般的な情報を回答してください。

#     {context}
# """
SYSTEM_PROMPT_INQUIRY = """
    あなたは社内情報特化型のアシスタントです。
    以下の条件に基づき、ユーザー入力に対して回答してください。

    【条件】
    1. ユーザー入力内容と以下の文脈との間に関連性がある場合のみ、以下の文脈に基づいて回答してください。
    2. ユーザー入力内容と以下の文脈との関連性が明らかに低い場合、「回答に必要な情報が見つかりませんでした。」と回答してください。
    3. 憶測で回答せず、あくまで以下の文脈を元に回答してください。
    4. できる限り詳細に、マークダウン記法を使って回答してください。
    5. マークダウン記法で回答する際にhタグの見出しを使う場合、最も大きい見出しをh3としてください。
    6. 複雑な質問の場合、各項目についてそれぞれ詳細に回答してください。
    7. CSVデータからの情報の場合、該当する社員や項目を表形式やリストで分かりやすく整理して回答してください。
    8. 「〜の社員」「〜に所属」「〜部の従業員」などの質問には、該当する全ての人物を漏れなく列挙してください。
    9. 部署に関する質問の場合、文脈に記載された「部署:○○部」の情報のみを参照し、スキルセットや保有資格の内容で判断しないでください。
    10. 「■ ○○部」というセクション内に記載されている従業員のみが、その部署に所属しています。
    11. 必要と判断した場合は、以下の文脈に基づかずとも、一般的な情報を回答してください。

    【文脈】
    {context}
"""
### 2026/01/02 m.sonoki mod end


# ==========================================
# LLMレスポンスの一致判定用
# ==========================================
INQUIRY_NO_MATCH_ANSWER = "回答に必要な情報が見つかりませんでした。"
NO_DOC_MATCH_ANSWER = "該当資料なし"


# ==========================================
# エラー・警告メッセージ
# ==========================================
COMMON_ERROR_MESSAGE = "このエラーが繰り返し発生する場合は、管理者にお問い合わせください。"
INITIALIZE_ERROR_MESSAGE = "初期化処理に失敗しました。"
NO_DOC_MATCH_MESSAGE = """
    入力内容と関連する社内文書が見つかりませんでした。\n
    入力内容を変更してください。
"""
CONVERSATION_LOG_ERROR_MESSAGE = "過去の会話履歴の表示に失敗しました。"
GET_LLM_RESPONSE_ERROR_MESSAGE = "回答生成に失敗しました。"
DISP_ANSWER_ERROR_MESSAGE = "回答表示に失敗しました。"